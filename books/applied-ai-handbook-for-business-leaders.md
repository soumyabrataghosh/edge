# Applied AI: A Handbook For Business Leaders

* Author:  Mariya Yao, Adelyn Zhou, Marlene Jia
* GoodReads: [Applied Artificial Intelligence: A Handbook For Business Leaders](https://www.goodreads.com/book/show/40479164-applied-artificial-intelligence?ac=1&from_search=true&qid=ZGo7vB7G69&rank=1)

## Highlights

* experts in the field of AI prefer to use the term Artificial General Intelligence (AGI) to refer to machines with human-level or higher intelligence, capable of abstracting concepts from limited experience and transferring knowledge between domains. AGI is also called “Strong AI” to differentiate from “Weak AI” or “Narrow AI," which refers to systems designed for one specific task and whose capabilities are not easily transferable to other systems.
* Differentiating between methods that are AI and those that are not can be tricky, and there is often overlap. You will find that simpler approaches often outperform complex ones in the wild, even if they’re intellectually less “advanced."
* Inferential statistics is used to draw conclusions that apply to more than just the data being studied.
* Data mining is the automation of exploratory statistical analysis on large-scale databases,
* The goal of data mining is to extract patterns and knowledge from large-scale datasets so that they can be reshaped into a more understandable structure for later analysis.
* Symbolic systems are programs that use human-understandable symbols to represent problems and reasoning.
* Machine learning enables computers to learn without being explicitly programmed.
* Supervised learning occurs when the computer is given labeled training data, which consists of paired inputs and outputs (e.g. an image of a cat correctly labeled as “cat”), and learns general rules that can map new inputs to the correct output.
* Unsupervised learning occurs when computers are given unstructured rather than labeled data, i.e. no input-output pairs, and asked to discover inherent structures and patterns that lie within the data. One common application of unsupervised learning is clustering, where input data is divided into different groups based on a measure of “similarity."
* Deep learning is a subfield of machine learning that builds algorithms by using multi-layered artificial neural networks, which are mathematical structures loosely inspired by how biological neurons fire. Neural networks were invented in the 1950s, but recent advances in computational power and algorithm design—as well as the growth of big data—have enabled deep learning algorithms to approach human-level performance in tasks such as speech recognition and image classification.
* Google replaced previous statistical methods for machine translation with neural networks to achieve superior performance.(4) Microsoft announced in 2017 that they had achieved human parity in conversational speech recognition.
* In practice, using simpler AI approaches like older, non-deep-learning machine learning techniques can produce faster and better results than fancy neural nets can. Rather than building custom deep learning solutions, many enterprises opt for Machine Learning as a Service (MLaaS) solutions from Google, Amazon, IBM, Microsoft, or leading AI startups.
* Deep learning also suffers from technical drawbacks. Successful models typically require a large volume of reliably-labeled data, which enterprises often lack. They also require significant and specialized computing power in the form of graphical processing units (GPUs) or GPU alternatives such as Google’s tensor processing units (TPUs). After deployment, they also require constant training and updating to maintain performance.
* Probabilistic programming enables us to create learning systems that make decisions in the face of uncertainty by making inferences from prior knowledge.
* experts see probabilistic programming as an alternative approach in areas where deep learning performs poorly, such as concept formulation using sparse or medium-sized data. Probabilistic programs have been used successfully in applications such as medical imaging, machine perception, financial predictions, and econometric and atmospheric forecasting.
* Probabilistic programming is emerging as a hot area in technical research, but it has yet to be productized and operationalized for enterprise performance to the same degree that machine learning and deep learning have.
* Ensemble methods, for example, combine different machine learning models or blend deep learning models with rule-based models.
* There are four broad categories of ensembling: bagging, boosting, stacking, and bucketing. Bagging entails training the same algorithm on different subsets of the data and includes popular algorithms like random forest. Boosting involves training a sequence of models, where each model prioritizes learning from the examples that the previous model failed on. In stacking, you pool the output of many models. In bucketing, you train multiple models for a given problem and dynamically choose the best one for each specific input. Other techniques, such as evolutionary and genetic algorithms, are used in practice for generative design and in combination with neural networks to improve learning.
* Systems That Predict are systems that are capable of analyzing data and using it to produce probabilistic predictions.
* Statistics power most Systems That Predict, but predictions are only as good as the data being used.
* Daniel Goleman, a psychologist and author of the book Emotional Intelligence, believes that our emotional intelligence quotient (EQ) is more important than our intelligence quotient (IQ) in determining our success and happiness.
* human toddler only needs to see a single tiger before developing a mental construct that can recognize other tigers. If humans needed to see thousands of tigers before learning to run away, our species would have died out from predation long ago.
* A common pattern observed in both academia and industry engineering teams is their propensity to optimize for tactical wins over strategic initiatives. While brilliant minds worry about achieving marginal improvements in competitive benchmarks, the nitty-gritty issues of productizing and operationalizing AI for real-world use cases are often ignored. Who cares if you can solve a problem with 99 percent accuracy if no one needs that problem solved?
* Designing and implementing the infrastructure needed for enterprise-scale AI requires a strong and dedicated technology team that can develop internal application programming interfaces (APIs) to standardize access to both data and your company’s internal business technology. Doing so will enable your company to streamline enterprise-wide data analysis, accelerate product development, and respond more quickly in evolving markets. Internal APIs will also reduce the communication overhead needed to hunt down specific data, negotiate access, and interpret variations. You will also avoid duplicating software development work across different departments that have overlapping needs and goals.
* Here are some things that you can do to win support from your organization. Focus on Revenue Potential A key strategy is to appeal to your business leaders about the potential of increasing the bottom line. AI can save time and energy, reduce costs, and increase profits, which then provide executives an opportunity to grow their business lines and advance their careers. Stay Ahead of the Competition The fear of missing out (FOMO) is also a very strong motivating force. If business unit leaders fail to take action, emphasize that they are setting themselves up to fall behind competitors who are jumping on new technology. Not investing in the organizational and technical requirements to adopt AI may mean falling so far behind that you’re unable to compete in the future. Start Small and Show Early Wins Pick a smaller, sure-win project to demonstrate possibilities. While returns may be limited, an early success will give you confidence when you request that the project scope be expanded. Aim for something with a short time horizon that can be completed with a small task force. For example, in customer care, Nuance recommends routing a tiny portion of customer support queries to an AI system at the onset. Initially, an automated support system can answer 20 to 30 percent of frequently asked questions, but accuracy can increase to over 80 percent and expand to more topics as the system learns over time.
* Don’t Call It Artificial Intelligence When pitching your project, emphasize the value that new technology can deliver instead of the technical details of implementation.
* Allay Fears of Sudden Job Loss Given the negative media hype surrounding AI, your employees understandably have concerns over their job security. You can allay these fears and promote a healthy work environment in which both humans and machines cooperate and thrive.
* Mathematical Aptitude A background in mathematics and statistics is far more valued in machine learning than in traditional software engineering.
* Curiosity Training ML algorithms requires a constant sense of curiosity.
* Creativity As ML tools and methodologies are still relatively new, the ability to think through ideas and to come up with novel ways to tackle a problem is highly valued.
* Perseverance Artificial intelligence research is an ever-evolving pursuit.
* Rapid Learning AI is evolving rapidly and keeping up-to-date with the accomplishments in the field is critical.
* Passion for Your Problem “We get plenty of resumes from people with talented machine learning and data science backgrounds,” says Zhen Jiang, Lead Analytics Supervisor at Ford Motor Company. “What I am much more concerned about is whether they have a passion for cars and mobility.”
* Knowing When to Stop Perfect is the enemy of the good. Look for pragmatic applicants who recognize that a “good enough” model that meets product deadlines is better than a model that sits in development awaiting “just a few more tweaks.”
* Once you have assessed that your organization has the requisite culture, leadership, and talent to succeed in AI initiatives, the next step is to identify business opportunities with the highest return on investment (ROI).
* Perform Opportunity Analysis
    * Gap Analysis: Gap analysis is used to assess where your business is versus where you would like it to be. The methodology relies on benchmarking, critical analysis, and action planning.
    * Goal and Objectives: Setting The first step to performing a gap analysis is to create clear goals. The objectives that you select can vary between companies, organizations, products, processes, etc. The key is to articulate useful goals that have clear objectives with appropriate, well-defined metrics for success.
    * Benchmarking: Benchmarking helps you to understand where you are and where you want to be. If you want to assess whether automation is worthwhile, you may want to compare your current performance with the performance of organizations that have already implemented automation. If it’s difficult to get department-level metrics for competitors, consider hiring experts who have worked extensively with many companies to help you establish benchmarks. Don’t limit yourself to data from your own industry. Technology companies have disrupted many traditional business models, so look beyond the obvious comparisons.
    * Gap Identification: After formulating goals and benchmarking your current performance against others, list all of the features associated with each objective that you want to achieve. Further break down those goals into their constituent parts. Compare where you are against where you want to be and identify the gaps between your current situation and your goals. Where are the biggest gaps? Complete this step for each goal that you are analyzing.
    * Action Planning: Once gaps have been identified, create a plan of action to address deficient areas. What steps will you need to take to achieve them? How can you use automation to close this gap? The next step is to create a project plan that identifies how to fill those gaps. You can use a SWOT Analysis approach or our AI Strategy Framework, described in the next section, to hone in on opportunities.
* SWOT Analysis: SWOT stands for Strengths, Weaknesses, Opportunities, and Threats. This popular business framework can also be used to evaluate AI opportunities. Use this approach to uncover opportunities as well as potential weaknesses that you need to mitigate. You can apply the analysis to your own company as well as to competitors. In a SWOT analysis, first evaluate the internal factors affecting your business.  What are your strengths? What makes the department so great? Which projects or teams are finding success? Next consider your business’s weaknesses. Which projects or departments are unprofitable? What resources do you lack? What can be done better? The second half of a SWOT analysis considers the external factors, such as opportunities and threats, in the marketplace. What are your business goals? How can new technologies such as AI drive your enterprise forward?
* “Building an AI-Ready Culture,” an analytical culture is required to succeed in AI initiatives since accurate, centralized data is the foundation for developing effective machine learning solutions.
* According to Michael Li, Head of Analytics and Data Science at LinkedIn, an organization can have five levels of analytics sophistication:(60) Data: What Happened? At this level, organizations want to use descriptive and exploratory statistics to answer fundamental business questions about what has happened in the past.
* Information and Knowledge: Why Did It Happen? Once you and your executives are clear on what has happened in your business in the past, the next step is to understand why.
* Intelligence: What Will Happen? All businesses want to make key predictions, such as whether a prospect will become a paying customer or if an existing customer is in danger of churning.
* Insights: What’s the Best That Could Happen? Machine learning can also be used to discover opportunities you weren’t aware of, such as new customer segments you can target, more effective messaging and processes for your sales and marketing functions, or a superior product design that improves retention.
* Change and Impact: How Can We Automate Continuous Transformation? The ultimate outcome for an analytics practice is to tighten and automate the feedback loop between data, insights, action, and results.
* Artificial intelligence techniques are most economically used to automate problems that are time-consuming, repetitive, and simple in scope. Most machine learning approaches also require large quantities of clean, trainable data. Just because a problem can be automated does not mean that an AI solution is appropriate. For example, using AI to generate an annual shareholder report may not be a good investment if you can easily hire analysts to do the work more cheaply than you can build or buy a software alternative. The task also requires strategic communication and contextual understanding, which modern AI technologies struggle with.
* Here are key questions to ask when evaluating whether your problem needs an AI solution:
     * Is this a process that can be solved using machine learning? Break down the process into its components to determine inputs, outputs, and contingencies. How long does it take to perform? How often is each step taken? How many people perform the same task? This gives a sense of the opportunity size for automation.
     * Is it suitable for machine learning? Identify the decision-making process for each task component. Do answers to questions come to you immediately, or do they require longer deliberation? Furthermore, if multiple people were answering the same question, would they all reach the same conclusion? Machine learning is best used to replicate human decisions for tasks where correct answers are clear and measurable.
     * Is data available? Are there sufficient volumes of relevant data associated with the process from which an algorithm can learn? How easily accessible is the data? Do you have a technical team that can manage and analyze the data? How long will they need to transform the data into a usable format?
* However, the mere existence of a solution does not mean that it’s definitely right for your company. In the digital era, data is the hottest commodity. Many executives tell us that they are concerned with the potential business impact of sharing data and outsourcing technical expertise.
* Building Internally There are several important criteria to consider when thinking about building in-house. First, determine whether your technology is a core functionality of your business.
* Second, evaluate the availability of in-house talent. There is a massive skills shortage in the field of artificial intelligence.
* Third, set a timeline for deployment. Even if your company has the talent and the data to build a custom solution, you may not have access to them until higher-priority projects have been addressed. In many instances, your fastest solution may be a proof-of-concept with an external vendor.
* Fourth, assess the availability of data for your project. Having tons of data doesn’t mean that you have the right data.
* Finally, total ownership cost is a key factor when deciding whether to build or buy.
* Evaluating Vendors: Given the hype, many third-party vendors claim to “use AI” but are really using the phrase as a marketing tool. When looking at our Machine Intelligence Continuum from Chapter 2, you’ll see that most vendors are actually using technologies that fall under Systems That Act and Systems That Predict, not Systems That Learn. To differentiate between value and hype, be sure to probe any prospective solution provider on the following: Access to Data Many companies are developing machine learning algorithms, but those with access to large volumes of proprietary data have an advantage.
* Domain Specificity Companies with many clients in the same industry can leverage their knowledge across customers.
* Team Talent AI is a growth industry facing a massive skills shortage. When you evaluate a provider, look at the backgrounds and qualifications of the founders, key engineers, and product teams on their website or LinkedIn page.
* ROI Metrics When choosing between potential partners, evaluate how they measure successful outcomes.
    * Client Experience: Evaluate a company's expertise by examining its client list.
    * Ease of Integration: Solution providers will quote integration timelines that range from a few days to a few months.
    * Pricing: Find a company that has a pricing model aligned with your business goals.
    * Security: With cybersecurity breaches at the forefront of the news these days, it’s essential that your technology partner addresses security issues.
    * Data Connection: Does the prospective product offer seamless connections with the other enterprise tools on which you depend, such as your data and analytics provider or CRM system?
    * Language Support: If you’re working on a consumer-facing global product, such as a conversational agent or sentiment analysis, your solution may need to support additional languages.
    * Professional Support: Most AI systems will need to be continually trained and updated.
    * Regulatory Requirements: Legislation may require your business to explain critical technology decisions.
    * Limits of Use: No third-party solution will be perfect for your use case, so it is equally important to understand the features as well as the limitations of the software that you decide to buy.
    * Competitive Landscape: How does a specific vendor stack up against competition in the same industry or vertical? Since AI is heavily dependent on data, vendors that are unable to capture a sufficient portion of the market may find themselves falling further and further behind the market leaders. This may negatively impact their ability to deliver an excellent product or service to you, their customer.
* Many vendor solutions which purport to use AI are point solutions which address a single problem very well but can’t support the complex workflows you need to do business.
* Building a fully customized, in-house solution means you can build an end-to-end system that addresses all required aspects of your business workflow and technical integrations. You can optimize the entire pipeline, not just algorithms for specific tasks. You have a high degree of flexibility and can specialize in developing capabilities unique to your organization. Finally, you can design the exact security infrastructure you need to meet company and industry standards. In
* Popular open-source solutions for building big data and AI platforms include Apache Hadoop and Spark, H2O.ai, Scikit-Learn, and TensorFlow.
* However, a 2017 McKinsey report found that 41 percent of businesses reported that the uncertain return on investments was one of the biggest barriers preventing them from adopting AI.
* First, you can assess its revenue creation ability, most notably in external-facing departments such as sales, marketing, and customer service. AI can identify new potential customers for the sales team, facilitate personalization to improve conversion rates and decrease churn, and power customer service bots to provide higher quality service and generate repeat business.
* Decreasing Costs Measuring the ability to reduce costs is another popular way to assess returns on AI investments. AI promises greater operational efficiencies, predominantly in middle and back office functions, such as in legal, finance and accounting, operations, and human resources.
* However, efficiency alone is not valuable. Focus instead on the increased output or decreased human capital costs that are made possible by efficiency gains. Don’t forget to include potential cost reductions that result from improved compliance and decreased legal risks.
* Finally, what is the opportunity cost of inaction?
* Portfolio Approach: Consider taking a portfolio or a venture capitalist approach to evaluating returns on AI projects.(76) View these early investments as research and development (R&D) ventures and assume that lots of failures will accompany each success. Many of the projects with the biggest ROI also take the longest to mature, require the most investment, and involve the most risk. Therefore, select a variety of projects based on their respective investment requirements, expected time to results, and likelihood of success. Schedule the experiments across multiple quarters and intersperse sure wins with riskier projects. If you’re restricted to testing one project at a time, prioritize likely wins in order to gain credibility and flexibility for future projects. Pick the Right “True North” Metric How can you tell if your AI strategy is creating long-term and sustainable value? Answering this question can be the most difficult and most impactful step of your machine learning process. Even after you've ascertained that an AI initiative is likely to positively impact the bottom line of your business, you need to define a more specific "true north" metric for each major project in order to keep your machine learning projects on the right trajectory.
* Facebook's true north metric for platform growth is the number of members who connect with ten friends in seven days.(77) Just having a user sign up for an account is insufficient to inspire the engagement rates that Facebook needs to later monetize that user through advertising. Similarly, Slack focuses on teams that have exchanged at least 2,000 messages.(78) Once a team has reached this threshold of usage, they're much more likely to stick around and eventually upgrade to paid plans.
* Identifying the right true north metric can be a challenge. Ask yourself the following questions to avoid the common mistakes executives make. Is this a metric everyone can understand? Avoid using jargon or overly technical terminology when defining your true north metric. You want to align your entire company, not just a handful of domain experts, to your AI strategy goals. Optimize for simplicity, transparency, and ease of communication. Is this a vanity or a success metric? You may have tons of page views, but those aren't useful unless you are also converting those visitors into more paying customers. Be sure your true north metric is an accurate proxy for success. Is this a leading or a lagging indicator? Lagging indicators like post-purchase behavior may be useful for evaluating the condition of your business but they may come too late to inform your daily business decisions. Is this a relative or absolute metric? Absolute metrics such as the total number of registered users will always increase. Don't fall into the trap of using such metrics to stroke your ego. A relative metric such as the number of monthly active users (MAU) can be used to compute a rate of change for comparative analysis between different periods. Is this metric actionable? Do you know what you will do if you don't hit your minimum thresholds for your true north metrics? What about when your performance exceeds expectations? An effective metric needs to help you filter out unproductive follow-up actions and prioritize impactful ones. Is the metric tracked and measured correctly? Adjustments almost always need to be made to correctly compare results from different periods. For example, you may need to account for seasonality or remove statistical anomalies such as outliers. You'll also need to perform a sanity check to make sure that the data sources used to compute your metric are free of bias and mistakes.
* Business leaders who want to lead AI initiatives at their companies should develop a high-level understanding of how machine learning models are built, even if you are not responsible for writing the code yourself. Your willingness to educate yourself on general technical details will improve your credibility and communication with the engineers on your team.
* The foundation of artificial intelligence is data. Even perfectly-implemented algorithms will fail without the right data. This is no different from a human expert arriving at the wrong conclusions after being given the wrong facts.
   * Accuracy: Accuracy gives the percentage of classifications that were correctly made.
   * Precision: Precision measures the percentage of true outcomes that were correctly identified out of all of the true classifications that were made.
   * Recall: Recall measures the percentage of true outcomes that were correctly classified as being true. In other words, recall characterizes a model’s ability to identify all of the instances that we should care about in a dataset.
   * Trade-offs: There’s a trade-off between optimizing the precision and recall of a model. The nature of your task will determine whether it’s more important to maximize precision, to maximize recall, or to achieve a balance between the two.
* Common Mistakes With Machine Learning Models
   * Underfitting: Underfitting occurs when your model is too simple to capture the complexities of your underlying data.
   * Overfitting: Overfitting occurs when your model does not generalize well outside of your training data.
   * Machine learning projects benefit from following a structured workflow, which starts with clearly defining business goals.
   * Of all of the machine learning approaches currently in use, supervised machine learning produces the most business value. The core of supervised machine learning is a mathematical model that describes how an algorithm makes predictions after being trained with historical data. The goal of training is to develop a model capable of mapping each input to a target output.
* A typical machine learning process follows these steps:
   * Define Business Goal: Carefully define your highest priority goal and your key performance indicators (KPI). Keep in mind that optimizing for everything means optimizing for nothing. Choosing too many KPIs will invariably result in conflicts where trying to boost one leads to a performance drop in another. Try to balance internal business metrics, such as revenue, with metrics related to the customer experience. Avoid vague requests, such as “increase revenue." Increasing revenue could result from entering new markets, cross-promoting products, or reducing customer churn, all of which will require different technical approaches.
   * Frame the Problem: Once you have defined your priority business goal and KPI, and you’ve identified data and technology dependencies, then your data scientists and engineers can frame your problem in machine learning terms.
   * Centralize Data: If your desired data resides in different data warehouses or across various departments, it will require a coordinated, cross-functional effort to collate everything into a single training dataset.
   * Clean Data: Prepare the data for processing by filling in missing values and correcting flaws.
   * Split Data: If you use all of your data to train a model, then you cannot easily check to see if that model will perform well on new data.
   * Train Model: Model training begins once the data has been split and algorithmic approaches are selected.
   * Validate and Test: Model Measure the model’s accuracy by using your validation and test datasets.
   * Deploy Model: Finally, deploy the model in your business to reap the benefits of this new technology.
   * Monitor Performance: Machine learning models will decay in performance if they are not regularly retrained on fresh data.
   * Iterate: Machine learning models are never “done,” in the sense that they will need continuous monitoring, iteration, and retraining to maintain required levels of performance over time.
   * Maintain an Experimental Mindset: Science experiments fail 99 percent of the time. As an executive, you’d be fired if you failed 99 percent of the time. Corporate risk aversion prevents most business leaders from leading bold experiments. However, early AI investments can be classified as R&D spending, and they should be regarded as innovation opportunities with potentially exponential returns.
* Consistent testing and iteration are critical to AI systems that learn and improve over time. The vast majority of tests will fail initially.
* Overall, successful MLaaS systems have the following characteristics(89): Algorithm-agnostic. The platform supports numerous machine learning algorithms and innovative combinations of these algorithms. Reusable. Each machine learning algorithm can be reused in other applications. Simple. The system is easy for engineers of varying levels of technical experience to understand and use. Over time, the steps should become fully automated. Centralized knowledge. Information on past experiments, including results, is easily accessible for future reference. Flexible. The platform is capable of handling a variety of data types and learning tasks specific to your company and industry. Reliable and scalable. The platform remains resilient and be able to scale with high volumes of data during both the training and production phases. Intuitive user interface (UI). The system has a simple user interface to allow engineers and even non-technical domain experts to easily manage experiments as well as visualize and compare outputs.
* Iteration and Improvement Machine learning models are not static. Your model will need to be retrained as new data becomes available or as external conditions change. The frequency of updates will depend on your algorithm, the situation, and the availability of data.
* Models are typically retrained every few weeks or months, or when there is a substantial change in external conditions that fundamentally changes the model trajectory.
* Current Obstacles Companies generate revenue by either cutting costs or finding new ways to make money, with the first being generally more straightforward than the second. Current AI-based solutions are very good at reducing inefficiencies in the workplace. By handing off repetitive tasks to software, employees have more time and energy to spend on high-value tasks.
* Customer Segmentation Customers have different values, preferences, and behaviors. You may be missing opportunities to make meaningful connections if you treat them the same way.
* Traditionally, qualifying potential leads requires a salesperson to make cold calls or engage in conversations, first to identify the right decision-maker, and then to assess the possibility of a purchase. However, this process is tedious, and a salesperson has to make a lot of unproductive calls before identifying an actual customer. Recent developments in natural language processing, understanding, and generation enable software to automatically handle outbound queries, process prospect replies, and alert salespeople to high-potential opportunities for follow-up.
* Sales Development Once a lead has been qualified, a salesperson takes over to develop a relationship that will hopefully culminate in a sale. Unfortunately, administrative tedium, such as scheduling demos, follow-ups, and a myriad of other social touch points, can consume a large part of a salesperson’s day. Artificial intelligence can be used to analyze the contents of email exchanges, extract schedule preferences, and automatically set meetings. Conversica, for example, uses natural language processing (NLP) to verify contact information, collect purchase requirements, and even set appointments automatically.
